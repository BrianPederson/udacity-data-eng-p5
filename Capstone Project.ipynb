{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "<font size=3>\n",
    "Using several datasets provided by Udacity, build a dimensional star schema data model that can be used for simulated data analysis queries related to I94 tourist data as well as weather data (average temperature). The primary (large volume) dataset consists of 12 months of US Government I94 immigration data. This is supplemented with a \"conformed\" dataset containing average temperatures at the grain of year, month, state which is compatible with the year, month and destination state present in the I94 dataset. The project utilizes various tools covered in the course such as PostgreSQL, Pandas, Spark, etc.  \n",
    "</font>\n",
    "  \n",
    "The project follows these steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up\n",
    "\n",
    "<font size=2>\n",
    "Note that due to this framework the \"flow\" of data from source to target for the various datasets is necessarily discontiguous and perhaps a little more difficult to follow.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 0: Initialize Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### Note if this is not being executed from the development workspace please remember to load additional datafiles from more_data.tar.gz into data/ directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import json\n",
    "import csv\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Note need to install pyarrow library prior to running this notebook. From command line execute:\n",
    "# pip install pyarrow\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set num_days which determines what subset of days from January, April, July, October of 2016 will be used.\n",
    "# note that setting num_days = 2 will result in approximately 1M rows being loaded into the primary fact table i94_f.\n",
    "# if num_days = 1 the entire notebook can execute in approx 15 minutes; num_days = 2 in approx 25 minutes...\n",
    "num_days = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Set up the PostgreSQL database environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# connect to default database\n",
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=studentdb user=student password=student\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# be careful with this since it recreates the database environment...\n",
    "\n",
    "# create capstone database with UTF8 encoding\n",
    "cur.execute(\"DROP DATABASE IF EXISTS capstone\")\n",
    "cur.execute(\"CREATE DATABASE capstone WITH ENCODING 'utf8' TEMPLATE template0\")\n",
    "\n",
    "# close connection to default database\n",
    "conn.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# connect to capstone database\n",
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=capstone user=student password=student\")\n",
    "conn.set_session(autocommit=True)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### Also enable SQL \"magic\" to be used as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: student@capstone'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://student:student@127.0.0.1/capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### Since the I94 dataset has many columns use the following option to enhance output formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The I94 dataset has many columns. This enhances the output formatting.\n",
    "pd.set_option('display.max_columns', 40)\n",
    "#pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "\n",
    "- Using several datasets provided by Udacity, build a dimensional star schema data model that can be used for simulated data analysis queries related to I94 tourist data as well as weather data (average temperature). The project utilizes various tools covered in the course such as PostgreSQL, Pandas, Spark, etc.    \n",
    "- The primary data source is the large I94 tourist dataset provided by Udacity for the project. This consists of 10s of millions of rows of I94 forms gathered by US Customs at Ports of Entry for the 12 months of 2016. This will be used to create the primary fact table of the resulting star schema. Note that only a subset of data will be loaded. \n",
    "- This will be supplemented by the global temperature dataset also provided by Udacity. This will be used to create a secondary fact table of the resulting star schema. The keys of the two fact tables will be designed so that they are 'conforming' and can be used together (via joins) if necessary. Since they have very different import feeds they will not be combined into a single fact table.   \n",
    "- In addition several small datasets have been extracted manually via text editor from the I94 Data Dictionary ```I94_SAS_Labels_Descriptions.SAS``` and will be used to create small dimensions for the resulting star schema.\n",
    "- One additional dataset was obtained over the web and it contains a cross reference of US Zip Codes, cities and states vs. latitude and longitude. It is used to enhance the world temperature dataset by adding a state code column to it so that it can be matched/joined efficiently against the I94 fact table.\n",
    "\n",
    "##### Data Source files and locations\n",
    "\n",
    "- Global Temperature Data - ```../../data2/GlobalLandTemperaturesByCity.csv```\n",
    "- I94 immigration Data - ```../../data/18-83510-I94-Data-2016/<12 monthly files>```\n",
    "- I94 State Codes - ```data/i94_states.csv```\n",
    "- I94 Country Codes - ```data/i94_countries.csv```\n",
    "- I94 Ports of Entry Codes - ```data/i94_ports_entry.csv```\n",
    "- I94 Visa Codes - ```data/i94_visas.csv```\n",
    "- I94 Mode Codes - ```data/i94_modes.csv```\n",
    "- Zip Code Latitude and Longitude Data - ```data/us-zip-code-latitude-and-longitude.csv``` \n",
    "\n",
    "##### Tools\n",
    "- The primary database tool is PostgreSQL. In an actual implementation the volume of data would lead towards a more scalable solution such as Redshift.\n",
    "  - One reason I'm using PostgreSQL is that I've been charged by AWS for processing during several earlier projects. The choice is partially budget related.\n",
    "  - However for purposes of the exercise I assume that it might be possible to use local PostgreSQL to prototype some elements of Redshift development.\n",
    "  - In reality it may not be practical to use PostgreSQL for prototyping and local development of Redshift applications since in some ways Redshift is a subset of PostgreSQL (they forked years ago) and in other ways Redshift is a superset of PostgreSQL (since AWS has added many capabilities to the base).\n",
    "- Secondary tools used for data exploration and ingestion include Pandas, Spark, Pyarrow, Parquet, etc.\n",
    "  - I'm using Pandas for data exploration as well as limited scale data ingestion processing. \n",
    "  - The Pyarrow library is installed and used in order to obtain a specific capability to ingest Parquet format files into Pandas dataframes.\n",
    "  \n",
    "##### End Solution - Star Schema Data Mart containing facts for I94 data and US City Temperature data.\n",
    "\n",
    "![Conceptual Model](conceptual_model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Pre-process Global (City) Temperature Data Source\n",
    "* Several datasets are in the form of simple csv files so load them into staging tables or final dimension tables if no transformations are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "stg_city_temp_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS stg_city_temp(\n",
    "    measure_dt DATE,                               -- dt\n",
    "    avg_temp NUMERIC(8,3),                         -- AverageTemperature\n",
    "    avg_temp_uncertainty NUMERIC(8,3),             -- AverageTemperatureUncertainty\n",
    "    city VARCHAR,\n",
    "    country VARCHAR,\n",
    "    latitude VARCHAR,\n",
    "    longitude VARCHAR)\n",
    "\"\"\")\n",
    "stg_city_temp_drop = \"DROP TABLE IF EXISTS stg_city_temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cur.execute(stg_city_temp_drop)\n",
    "cur.execute(stg_city_temp_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "city_temp_fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "with open(city_temp_fname, 'r', encoding='utf-8') as f:\n",
    "  next(f)   # skip the header row\n",
    "  cur.copy_from(f, 'stg_city_temp', sep=',', null='')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Pre-process the I94 tourism immigration dataset\n",
    "* The source data is in a proprietary SAS format.\n",
    "* First convert selected months of data (e.g. jan, apr, jul, oct) into Parquet format. \n",
    "* This is useful since the parquet files load quicker into pandas which is an advantage if running multiple times (i.e. during development).\n",
    "* The following utility will use a parquet version of the data if it already exists or create it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "                     config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "                     enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def xfer_sas_to_parq(month = 'jan'):\n",
    "  \"\"\"Utility function to transfer monthly I94 data from SAS format to parquet format. \n",
    "     Parameter is 3 char month code (e.g. 'jan', 'feb', etc.)\"\"\"\n",
    "  sas_file = 'i94_' + month + '16_sub.sas7bdat'\n",
    "  sas_path = '../../data/18-83510-I94-Data-2016/' + sas_file\n",
    "  parq_path = 'sas_data_16' + month\n",
    "    \n",
    "  # if the parquet directory already exists then skip this process\n",
    "  try:\n",
    "    open(parq_path, 'r')\n",
    "  except IsADirectoryError:\n",
    "    print(f'Target parquet directory {parq_path} for month \"{month}\" already exists so skip (re)loading it.')\n",
    "    return\n",
    "  except FileNotFoundError:\n",
    "    pass\n",
    "  except:\n",
    "    raise\n",
    "    \n",
    "  # otherwise load the SAS file into a Spark dataframe and then write it back to Parquet format\n",
    "  df_i94_spark = spark.read.format('com.github.saurfang.sas.spark').load(sas_path)\n",
    "    \n",
    "  print(f'Writing parquet directory {parq_path} for month \"{month}\".')\n",
    "  df_i94_spark.write.parquet('sas_data_16' + month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target parquet directory sas_data_16jan for month \"jan\" already exists so skip (re)loading it.\n",
      "Target parquet directory sas_data_16apr for month \"apr\" already exists so skip (re)loading it.\n",
      "Target parquet directory sas_data_16jul for month \"jul\" already exists so skip (re)loading it.\n",
      "Target parquet directory sas_data_16oct for month \"oct\" already exists so skip (re)loading it.\n"
     ]
    }
   ],
   "source": [
    "# Transfer selected monthly i94 data from SAS format into more efficient Parquet format.\n",
    "# This process only occurs if the transfer has not previously been performed.\n",
    "\n",
    "df_i94_spark = xfer_sas_to_parq('jan')\n",
    "\n",
    "df_i94_spark = xfer_sas_to_parq('apr')\n",
    "\n",
    "df_i94_spark = xfer_sas_to_parq('jul')\n",
    "\n",
    "df_i94_spark = xfer_sas_to_parq('oct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_i94_jan_pd has shape: (2847924, 28)\n",
      "df_i94_apr_pd has shape: (3096313, 28)\n",
      "df_i94_jul_pd has shape: (4265031, 28)\n",
      "df_i94_oct_pd has shape: (3649136, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load selected monthly i94 data into pandas dataframes from parquet files\n",
    "\n",
    "df_i94_jan_pd = pd.read_parquet('sas_data_16jan', engine='pyarrow')\n",
    "print('df_i94_jan_pd has shape:', df_i94_jan_pd.shape)  \n",
    "\n",
    "df_i94_apr_pd = pd.read_parquet('sas_data_16apr', engine='pyarrow')\n",
    "print('df_i94_apr_pd has shape:', df_i94_apr_pd.shape)  \n",
    "\n",
    "df_i94_jul_pd = pd.read_parquet('sas_data_16jul', engine='pyarrow')\n",
    "print('df_i94_jul_pd has shape:', df_i94_jul_pd.shape)  \n",
    "\n",
    "df_i94_oct_pd = pd.read_parquet('sas_data_16oct', engine='pyarrow')\n",
    "print('df_i94_oct_pd has shape:', df_i94_oct_pd.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Process small static I94 dimensions harvested from data dictionary I94_SAS_Labels_Descriptions.SAS\n",
    "* These small static dimensions can be processed directly into the target star schema table formats.\n",
    "* However these datasets were manipulated manually via text editor to extract the data from the I94 data dictionary.\n",
    "* This seems reasonable to do since these are static, one time only exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_states_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS i94_states_d(\n",
    "    state_code VARCHAR PRIMARY KEY,\n",
    "    state_name VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "i94_states_drop = \"DROP TABLE IF EXISTS i94_states_d\"\n",
    "\n",
    "cur.execute(i94_states_drop)\n",
    "cur.execute(i94_states_create)\n",
    "\n",
    "# Note that MP/Northern Mariana Islands, and OT/OTHER were added to the csv file manually.\n",
    "i94_states_fname = 'data/i94_states.csv'\n",
    "copy_command = \"\"\"\n",
    "COPY i94_states_d FROM STDIN WITH ( FORMAT csv, HEADER, DELIMITER ',' , NULL '' , QUOTE '''' )\n",
    "\"\"\"\n",
    "with open(i94_states_fname, 'r', ) as f:\n",
    "  cur.copy_expert(copy_command, f)\n",
    "conn.commit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_countries_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS i94_countries_d(\n",
    "    country_code VARCHAR PRIMARY KEY,\n",
    "    country_name VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "i94_countries_drop = \"DROP TABLE IF EXISTS i94_countries_d\"\n",
    "\n",
    "cur.execute(i94_countries_drop)\n",
    "cur.execute(i94_countries_create)\n",
    "\n",
    "# need to use copy_expert() because it allows use of PostgreSQL COPY command quote option. \n",
    "# Single quotes are needed to encapsulate some commas in country name column.\n",
    "i94_countries_fname = 'data/i94_countries.csv'\n",
    "copy_command = \"\"\"\n",
    "COPY i94_countries_d FROM STDIN WITH ( FORMAT csv, HEADER, DELIMITER ',' , NULL '' , QUOTE '''' )\n",
    "\"\"\"\n",
    "with open(i94_countries_fname, 'r', ) as f:\n",
    "  cur.copy_expert(copy_command, f)\n",
    "conn.commit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_ports_entry_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS i94_ports_entry_d(\n",
    "    port_code VARCHAR PRIMARY KEY,\n",
    "    port_of_entry VARCHAR,\n",
    "    state_code VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "i94_ports_entry_drop = \"DROP TABLE IF EXISTS i94_ports_entry_d\"\n",
    "\n",
    "cur.execute(i94_ports_entry_drop)\n",
    "cur.execute(i94_ports_entry_create)\n",
    "\n",
    "# need to use copy_expert() because it allows use of PostgreSQL COPY command quote option. \n",
    "# Single quotes are needed to encapsulate some commas in port_of_entry column.\n",
    "i94_ports_entry_fname = 'data/i94_ports_entry.csv'\n",
    "copy_command = \"\"\"\n",
    "COPY i94_ports_entry_d FROM STDIN WITH ( FORMAT csv, HEADER, DELIMITER ',' , NULL '' , QUOTE '\"' )\n",
    "\"\"\"\n",
    "with open(i94_ports_entry_fname, 'r', ) as f:\n",
    "  cur.copy_expert(copy_command, f)\n",
    "conn.commit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_visas_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS i94_visas_d(\n",
    "    visa_code VARCHAR PRIMARY KEY,\n",
    "    visa_name VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "i94_visas_drop = \"DROP TABLE IF EXISTS i94_visas_d\"\n",
    "\n",
    "cur.execute(i94_visas_drop)\n",
    "cur.execute(i94_visas_create)\n",
    "\n",
    "i94_visas_fname = 'data/i94_visas.csv'\n",
    "with open(i94_visas_fname, 'r', ) as f:\n",
    "  next(f) # Skip the header row.\n",
    "  cur.copy_from(f, 'i94_visas_d', sep=',')\n",
    "conn.commit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_modes_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS i94_modes_d(\n",
    "    mode_code VARCHAR PRIMARY KEY,\n",
    "    mode_name VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "i94_modes_drop = \"DROP TABLE IF EXISTS i94_modes_d\"\n",
    "\n",
    "cur.execute(i94_modes_drop)\n",
    "cur.execute(i94_modes_create)\n",
    "\n",
    "i94_modes_fname = 'data/i94_modes.csv'\n",
    "with open(i94_modes_fname, 'r', ) as f:\n",
    "  next(f) # Skip the header row.\n",
    "  cur.copy_from(f, 'i94_modes_d', sep=',')\n",
    "conn.commit()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Predefine the I94 tourism immigration staging table\n",
    "\n",
    "* Note that this dataset was examined extensiviely via Pandas and SQL to determine which columns could be defined as BIGINT vs INT vs NUMERIC vs VARCHAR.\n",
    "* In addition there were many queries used to determine the characteristics of the contents of the various columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "stg_i94_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS stg_i94(\n",
    "    cicid BIGINT, -- PRIMARY KEY, \n",
    "    i94yr INT, \n",
    "    i94mon INT, \n",
    "    i94cit VARCHAR,    \n",
    "    i94res VARCHAR,    \n",
    "    i94port VARCHAR, \n",
    "    arrdate INT,          -- 19600101+\n",
    "    i94mode VARCHAR, \n",
    "    i94addr VARCHAR,      -- declared destination state of tourist - this is a dirty column\n",
    "    depdate INT,          -- 19600101+\n",
    "    i94bir INT,           -- actually this is age\n",
    "    i94visa VARCHAR,    \n",
    "    count INT, \n",
    "    dtadfile VARCHAR,     -- YYYYMMDD  this is a clean column\n",
    "    visapost VARCHAR, \n",
    "    occup VARCHAR, \n",
    "    entdepa VARCHAR, \n",
    "    entdepd VARCHAR, \n",
    "    entdepu VARCHAR, \n",
    "    matflag VARCHAR, \n",
    "    biryear INT, \n",
    "    dtaddto VARCHAR,      -- MMDDYYYY  this is a dirty column \n",
    "    gender VARCHAR, \n",
    "    insnum VARCHAR, \n",
    "    airline VARCHAR, \n",
    "    admnum VARCHAR, \n",
    "    fltno VARCHAR, \n",
    "    visatype VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "stg_i94_drop = \"DROP TABLE IF EXISTS stg_i94\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cur.execute(stg_i94_drop)\n",
    "cur.execute(stg_i94_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore the Data\n",
    "* A significant amount of data exploration was required to determine which datasets could be used and what cleaning and enhancements they might require. You can examine these notebooks for evidence of this activity: \n",
    "  * create_tables.ipynb\n",
    "  * data_wrangling_pandas.ipynb \n",
    "  * data_wrangling_sql.ipynb\n",
    "* Several other Udacity provided datasets such as Airport Codes and US Cities Demographics were explored. Based on that exploration it was decided not to use these datasets. \n",
    "  * In particular it was difficult to imagine semi-realistic, plausible queries that could be applied to the combination of I94 data with these datasets.\n",
    "  * So it was decided to concentrate on the I94 data and the Global City Temperature datasets to create the target star schema data mart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore City Temperature dataset\n",
    "* In order for the City Temperature data to be compatible as a \"conformed\" fact table with the I94 fact table a state code needs to be added to the former since it only contains City Names and Latitude and Longitude. These three form a unique key for the source dataset.\n",
    "* In order to add a State Code to the City Temperature dataset I determined that I would need a cross reference of City Name, Latitude, Longitude to US State Code.\n",
    "* Originally I thought I could construct such a cross reference from the data contained in the Udacity provided Airport Codes dataset. It has the necessary columns. However after exploring that dataset I found that it didn't have enough geographical coverage of the US.\n",
    "* The following is an example of some of the MANY data exploration exercises that was done to determine what data could be used. This query of the Global City Temperature dataset reveals that the latitude and longitude contained in the dataset do not correspond to the cities. The latitude and longitude is at the grain of a region and might point to a location more than 30 miles away from the city. You can clearly see that all of the cities in the Bay Area share the same values for Latitude and Longitude. \n",
    "* Based on queries like this it was determined that in order to have the city temperature data be compatible with the I94 dataset a better method would be needed to add a state column to this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "4 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>dt</th>\n",
       "        <th>avg_temp</th>\n",
       "        <th>city</th>\n",
       "        <th>country</th>\n",
       "        <th>latitude</th>\n",
       "        <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2013-09-01</td>\n",
       "        <td>9.52</td>\n",
       "        <td>Newark</td>\n",
       "        <td>United States</td>\n",
       "        <td>40.99N</td>\n",
       "        <td>74.56W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2013-09-01</td>\n",
       "        <td>9.52</td>\n",
       "        <td>Jersey City</td>\n",
       "        <td>United States</td>\n",
       "        <td>40.99N</td>\n",
       "        <td>74.56W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2013-09-01</td>\n",
       "        <td>9.52</td>\n",
       "        <td>New York</td>\n",
       "        <td>United States</td>\n",
       "        <td>40.99N</td>\n",
       "        <td>74.56W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2013-09-01</td>\n",
       "        <td>9.52</td>\n",
       "        <td>Yonkers</td>\n",
       "        <td>United States</td>\n",
       "        <td>40.99N</td>\n",
       "        <td>74.56W</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.date(2013, 9, 1), Decimal('9.52'), 'Newark', 'United States', '40.99N', '74.56W'),\n",
       " (datetime.date(2013, 9, 1), Decimal('9.52'), 'Jersey City', 'United States', '40.99N', '74.56W'),\n",
       " (datetime.date(2013, 9, 1), Decimal('9.52'), 'New York', 'United States', '40.99N', '74.56W'),\n",
       " (datetime.date(2013, 9, 1), Decimal('9.52'), 'Yonkers', 'United States', '40.99N', '74.56W')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "select max(measure_dt) dt, round(avg(avg_temp),2) avg_temp, min(city) city, min(country) country, min(latitude) latitude, min(longitude) longitude\n",
    "  from stg_city_temp \n",
    " where country = 'United States'\n",
    "   --and city in ('San Francisco', 'Oakland', 'Berkeley', 'Vallejo', 'Sacramento', 'San Jose')\n",
    "   and city in ('New York', 'Jersey City', 'Newark', 'Yonkers')\n",
    " group by country, city\n",
    " order by latitude, longitude\n",
    " limit 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Process zip code vs latitute-longitude cross reference data\n",
    "\n",
    "* In order to be able to match data from the city temperature dataset to the I94 dataset we need to be able to enhance the former to include state codes. In its raw form the city temp dataset has a pseudo primary key of country and city compounded with Latitude and Longitude but no state code.\n",
    "* In order to enhance the city temperature dataset to include state codes in addition to city names we can use the latitude and longitude from this dataset in conjunction with a cross reference dataset which has city, state and latitude, longitude data elements.\n",
    "* Note that the provided airports dataset does have these data elements and this was considered as a possible source for the required cross reference data but there is not enough geographical coverage of US cities in that dataset so it was ultimately discarded.\n",
    "* An alternative dataset with zip code, state, city to latitude, longitude cross reference capability was obtained at:\n",
    "https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/information/\n",
    "* Data structure: Zip;City;State;Latitude;Longitude;Timezone;Daylight savings time flag;Geopoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "stg_zip_lat_lon_xref_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS stg_zip_lat_lon_xref(\n",
    "    zip VARCHAR,\n",
    "    city VARCHAR,\n",
    "    state VARCHAR,\n",
    "    latitude NUMERIC,\n",
    "    longitude NUMERIC,\n",
    "    timezone NUMERIC,\n",
    "    dst_flag NUMERIC,\n",
    "    geopoint VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "stg_zip_lat_lon_xref_drop = \"DROP TABLE IF EXISTS stg_zip_lat_lon_xref\"\n",
    "\n",
    "cur.execute(stg_zip_lat_lon_xref_drop)\n",
    "cur.execute(stg_zip_lat_lon_xref_create)\n",
    "\n",
    "zip_lat_lon_fname = 'data/us-zip-code-latitude-and-longitude.csv'\n",
    "with open(zip_lat_lon_fname, 'r', ) as f:\n",
    "  next(f) # Skip the header row.\n",
    "  cur.copy_from(f, 'stg_zip_lat_lon_xref', sep=';', null='')  # interpret empty string as NULL\n",
    "conn.commit()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>43191</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(43191,)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(*) from stg_zip_lat_lon_xref;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "2 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>zip</th>\n",
       "        <th>city</th>\n",
       "        <th>state</th>\n",
       "        <th>latitude</th>\n",
       "        <th>longitude</th>\n",
       "        <th>timezone</th>\n",
       "        <th>dst_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>94966</td>\n",
       "        <td>Sausalito</td>\n",
       "        <td>CA</td>\n",
       "        <td>38.068036</td>\n",
       "        <td>-122.740988</td>\n",
       "        <td>-8</td>\n",
       "        <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>94965</td>\n",
       "        <td>Sausalito</td>\n",
       "        <td>CA</td>\n",
       "        <td>37.855527</td>\n",
       "        <td>-122.49949</td>\n",
       "        <td>-8</td>\n",
       "        <td>1</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('94966', 'Sausalito', 'CA', Decimal('38.068036'), Decimal('-122.740988'), Decimal('-8'), Decimal('1')),\n",
       " ('94965', 'Sausalito', 'CA', Decimal('37.855527'), Decimal('-122.49949'), Decimal('-8'), Decimal('1'))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select zip, city, state, latitude, longitude, timezone, dst_flag from stg_zip_lat_lon_xref where city = 'Sausalito' limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### Perform one processing step which reduces the cross reference data down from zip code to city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "Done.\n",
      "30346 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "drop table if exists stg_city_lat_lon_xref cascade;\n",
    "create table stg_city_lat_lon_xref as \n",
    "select city, \n",
    "       state state_code, \n",
    "       round(avg(latitude),6) latitude, \n",
    "       round(avg(longitude),6) longitude, \n",
    "       min(timezone) timezone, \n",
    "       min(dst_flag) dst_flag, \n",
    "       count(*) zip_count\n",
    "  from stg_zip_lat_lon_xref\n",
    " group by state, city\n",
    ";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>city</th>\n",
       "        <th>state_code</th>\n",
       "        <th>latitude</th>\n",
       "        <th>longitude</th>\n",
       "        <th>timezone</th>\n",
       "        <th>dst_flag</th>\n",
       "        <th>zip_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Sausalito</td>\n",
       "        <td>CA</td>\n",
       "        <td>37.961782</td>\n",
       "        <td>-122.620239</td>\n",
       "        <td>-8</td>\n",
       "        <td>1</td>\n",
       "        <td>2</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Sausalito', 'CA', Decimal('37.961782'), Decimal('-122.620239'), Decimal('-8'), Decimal('1'), 2)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select * from stg_city_lat_lon_xref where city = 'Sausalito' limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleanse the I94 dataframes\n",
    "\n",
    "* Note that pandas imports the data by default with poorly defined datatypes: all numbers are float64; all strings are object. In addition np.nan/NaN values are used to represent null or missing data for both datatypes. The NaN value is not compatible with PostgreSQL (or any SQL database) which uses NULL for this purpose.\n",
    "  * Therefore it is necessary to remove the NaN values and replace with None/NULL prior to insert into PostgreSQL.\n",
    "  * Use the pandas notna() utility for this purpose.\n",
    "* Also take advantage of this step to utilize sampling to reduce the subset of data to be pulled from SAS/Pandas into PostgreSQL.\n",
    "  * One way to do this is to use a pandas query filter to pick an equivalent, representative subset of days from each of the months. \n",
    "  * So use several days of data starting with the 14th day of each of four seasonally representative months (January, April, July, October).\n",
    "  * Note that if 2 days of data are used then the total rows in the i94 fact table will be close to 1M which is a project requirement..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Note that num_days has been set above during Step 0. This is used in the next cells to slice/partition the source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sample_slice(df_i94, start_date, num_days = 1, tag = None):\n",
    "    \"\"\"Utility function to create a sample slice of data from an I94 dataframe.\n",
    "       Parameters: df_i94 - dataframe representing one month of I94 data \n",
    "                   start_date - start date for sample in character YYYY-MM-DD format\n",
    "                   num_days - number of days of data to include\"\"\"\n",
    "    if tag: print(f'Processing sample slice for {tag}')\n",
    "    \n",
    "    first_date = datetime.strptime('1960-01-01', \"%Y-%m-%d\")\n",
    "    slice_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    days_offset = (slice_date - first_date).days\n",
    "    \n",
    "    df_slice = df_i94.query('arrdate>=@days_offset & arrdate<(@days_offset + @num_days)')\n",
    "    print('slice has shape:', df_slice.shape)\n",
    "    return df_slice.where(pd.notna(df_slice), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample slice for 16jan\n",
      "slice has shape: (92151, 28)\n",
      "Processing sample slice for 16apr\n",
      "slice has shape: (107557, 28)\n",
      "Processing sample slice for 16jul\n",
      "slice has shape: (140666, 28)\n",
      "Processing sample slice for 16oct\n",
      "slice has shape: (130102, 28)\n"
     ]
    }
   ],
   "source": [
    "# obtain sample slices from four seasonally representative months\n",
    "\n",
    "df_jan = sample_slice(df_i94_jan_pd, '2016-01-14', num_days, tag='16jan')\n",
    "#display(df_jan.head(4))\n",
    "\n",
    "df_apr = sample_slice(df_i94_apr_pd, '2016-04-14', num_days, tag='16apr')\n",
    "#display(df_apr.head(4))\n",
    "\n",
    "df_jul = sample_slice(df_i94_jul_pd, '2016-07-14', num_days, tag='16jul')\n",
    "#display(df_jul.head(4))\n",
    "\n",
    "df_oct = sample_slice(df_i94_oct_pd, '2016-10-14', num_days, tag='16oct')\n",
    "#display(df_oct.head(4))\n",
    "\n",
    "# ... or alternatively use the entire month but prepare to wait awhile for this to complete ...\n",
    "#df_oct = df_i94_jan_pd.where(pd.notna(df_i94_oct_pd), None)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Transfer the I94 data from Pandas dataframes to PostgreSQL staging table.\n",
    "* Utilize the relatively efficient executemany() routine to bulk load data in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_i94(df, max_rows = 999_999_999, chunk_size = 10_000, tag = None):\n",
    "    \"\"\"Utility function to efficiently load i94 data from a pandas dataframe into a PostgreSQL staging table. \n",
    "       Parameters: df - dataframe to load; max_rows - maximum row cutoff; chunk_size - number of rows to load in each call to executemany()\n",
    "    \"\"\"\n",
    "    i94_table_insert = (\"\"\"\n",
    "    INSERT INTO stg_i94(cicid,i94yr,i94mon,i94cit,i94res,i94port,arrdate,i94mode,i94addr,depdate,i94bir,i94visa,count,dtadfile,\n",
    "                        visapost,occup,entdepa,entdepd,entdepu,matflag,biryear,dtaddto,gender,insnum,airline,admnum,fltno,visatype) \n",
    "    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "    --ON CONFLICT (cicid)\n",
    "    --  DO NOTHING\n",
    "    \"\"\")   \n",
    "    \n",
    "    if tag:\n",
    "        print(f'Processing data for {tag}')\n",
    "\n",
    "    tot_rows = len(df)\n",
    "    i = 0\n",
    "    buf = list()\n",
    "    for row in df.itertuples(index = False):\n",
    "        #print(f'loading buf[{i%chunk}] with row {i}')\n",
    "        buf.append(row)\n",
    "        if (i+1)%chunk_size==0 or (i+1) == max_rows or (i+1) == tot_rows:\n",
    "            print(f'dumping buffer sized {len(buf)} at row {i}')\n",
    "            try:   \n",
    "                cur.executemany(i94_table_insert, buf)\n",
    "                buf = list()\n",
    "            except Exception as f:\n",
    "                print(f)\n",
    "                print(i, row)\n",
    "        if (i+1)>=max_rows: break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for 16jan\n",
      "dumping buffer sized 10000 at row 9999\n",
      "dumping buffer sized 10000 at row 19999\n",
      "dumping buffer sized 10000 at row 29999\n",
      "dumping buffer sized 10000 at row 39999\n",
      "dumping buffer sized 10000 at row 49999\n",
      "dumping buffer sized 10000 at row 59999\n",
      "dumping buffer sized 10000 at row 69999\n",
      "dumping buffer sized 10000 at row 79999\n",
      "dumping buffer sized 10000 at row 89999\n",
      "dumping buffer sized 2151 at row 92150\n",
      "Processing data for 16apr\n",
      "dumping buffer sized 10000 at row 9999\n",
      "dumping buffer sized 10000 at row 19999\n",
      "dumping buffer sized 10000 at row 29999\n",
      "dumping buffer sized 10000 at row 39999\n",
      "dumping buffer sized 10000 at row 49999\n",
      "dumping buffer sized 10000 at row 59999\n",
      "dumping buffer sized 10000 at row 69999\n",
      "dumping buffer sized 10000 at row 79999\n",
      "dumping buffer sized 10000 at row 89999\n",
      "dumping buffer sized 10000 at row 99999\n",
      "dumping buffer sized 7557 at row 107556\n",
      "Processing data for 16jul\n",
      "dumping buffer sized 10000 at row 9999\n",
      "dumping buffer sized 10000 at row 19999\n",
      "dumping buffer sized 10000 at row 29999\n",
      "dumping buffer sized 10000 at row 39999\n",
      "dumping buffer sized 10000 at row 49999\n",
      "dumping buffer sized 10000 at row 59999\n",
      "dumping buffer sized 10000 at row 69999\n",
      "dumping buffer sized 10000 at row 79999\n",
      "dumping buffer sized 10000 at row 89999\n",
      "dumping buffer sized 10000 at row 99999\n",
      "dumping buffer sized 10000 at row 109999\n",
      "dumping buffer sized 10000 at row 119999\n",
      "dumping buffer sized 10000 at row 129999\n",
      "dumping buffer sized 10000 at row 139999\n",
      "dumping buffer sized 666 at row 140665\n",
      "Processing data for 16oct\n",
      "dumping buffer sized 10000 at row 9999\n",
      "dumping buffer sized 10000 at row 19999\n",
      "dumping buffer sized 10000 at row 29999\n",
      "dumping buffer sized 10000 at row 39999\n",
      "dumping buffer sized 10000 at row 49999\n",
      "dumping buffer sized 10000 at row 59999\n",
      "dumping buffer sized 10000 at row 69999\n",
      "dumping buffer sized 10000 at row 79999\n",
      "dumping buffer sized 10000 at row 89999\n",
      "dumping buffer sized 10000 at row 99999\n",
      "dumping buffer sized 10000 at row 109999\n",
      "dumping buffer sized 10000 at row 119999\n",
      "dumping buffer sized 10000 at row 129999\n",
      "dumping buffer sized 102 at row 130101\n"
     ]
    }
   ],
   "source": [
    "# load sample data from four seasonally representative months into PostgreSQL staging table\n",
    "\n",
    "load_i94(df_jan, tag='16jan')\n",
    "\n",
    "load_i94(df_apr, tag='16apr')\n",
    "\n",
    "load_i94(df_jul, tag='16jul')\n",
    "\n",
    "load_i94(df_oct, tag='16oct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore I94 staging dataset - perform data integrity checks\n",
    "* It appears the the i94addr column represents the ultimate destination state of the traveller within the US. There are a lot of bad code values in this column. This is mentioned in the data dictionary I94_SAS_Labels_Descriptions.SAS. The large preponderance of data in this column are US state and territory codes. \n",
    "* In order to 'cleanse' this column use the following update which will backfill NULL or questionable codes by using the state code of the port of entry as a reasonable best guess for ultimate destination within US. An alternative strategy would be to ignore these rows and/or set the questionable values to NULL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "6 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "        <th>i94addr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>20446</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1431</td>\n",
       "        <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>433</td>\n",
       "        <td>VQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>235</td>\n",
       "        <td>UN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>140</td>\n",
       "        <td>HA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>116</td>\n",
       "        <td>XX</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(20446, None),\n",
       " (1431, 'US'),\n",
       " (433, 'VQ'),\n",
       " (235, 'UN'),\n",
       " (140, 'HA'),\n",
       " (116, 'XX')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select count(*), i94addr \n",
    "  from stg_i94 \n",
    " where i94addr is null \n",
    "    or i94addr not in (select state_code from i94_states_d) \n",
    " group by i94addr \n",
    " order by 1 desc limit 6;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* It appears that the dtadfile date is clean. However the dtaddto date is dirty. There is one semi-standard non date string found in the data (i.e. 'D/S').\n",
    "* In addition there are many mal-formed dates as well. These will be zapped to NULL below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "7 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "        <th>dtaddto</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1098</td>\n",
       "        <td>00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>04272020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>11300002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>09222021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>16439</td>\n",
       "        <td>D/S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>12319999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>09132020</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1098, '00000000'),\n",
       " (1, '04272020'),\n",
       " (1, '11300002'),\n",
       " (1, '09222021'),\n",
       " (16439, 'D/S'),\n",
       " (1, '12319999'),\n",
       " (1, '09132020')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(*), dtaddto from stg_i94 where substr(dtaddto,5,4) not in ('2016', '2017', '2018', '2019') group by dtaddto;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "        <th>dtaddto</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1098</td>\n",
       "        <td>00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>16439</td>\n",
       "        <td>D/S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>`1132017</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1098, '00000000'), (16439, 'D/S'), (1, '`1132017')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(*), dtaddto from stg_i94 where dtaddto='00000000' or dtaddto not similar to '[0-9]*' group by dtaddto;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Cleaning City Temperature dataset\n",
    "* The City Temperature dataset is has city names and fuzzy, inaccurate latitude and longitude data but does NOT have a US State code. In order to use this with the I94 dataset which uses state codes, we need to modify/enhance this dataset to have state codes in addition to city names. This is necessary because many city names are not unique and exist across multiple states. For example cities such as Portland, Springfield, etc. may be found in many US states.\n",
    "* Filters are applied to the Global City Temperature dataset in this step.\n",
    "  * Only data for the United States is selected.\n",
    "  * Only data for the one year (2012) is selected.\n",
    "  * In addition, since this dataset as provided by Udacity is missing the year 2016 (all provided I94 data is from 2016), I have taken the liberty to 'convert' the 2012 data into simulated 2016 data by simply incrementing the year. In the real world I'd go back to the source of the dataset to find data covering 2016.\n",
    "  * denormalized columns for year and month are added to make this similar to th I94 dataset\n",
    "  * the latitude and longitude data is converted to numeric form\n",
    "* Next create a final cross reference enabling view which uses the zip/city cross reference file processed earlier. It matches based on:\n",
    "  * proximity of latitude and longitude between the city temp dataset and the zip city xref dataset  \n",
    "  * ranking cities by size based on how many zip codes are present in a city which prioritizes matches with mid to large cities over small towns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "Done.\n",
      "3084 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "drop table if exists stg_us_city_temp cascade;\n",
    "create table stg_us_city_temp as \n",
    "select measure_dt + interval '4 year' measure_dt,     -- cheat a little to simulate the year 2016 in the data\n",
    "       cast(extract(year from measure_dt) as int) + 4 measure_yr, \n",
    "       cast(extract(month from measure_dt) as int) measure_mon,\n",
    "       avg_temp,\n",
    "       avg_temp_uncertainty,\n",
    "       city,\n",
    "       cast('' as VARCHAR) as state_code,     -- placeholder\n",
    "       md5(city || latitude || longitude) as city_key,  -- quick and dirty PK/FK for parent/child tables\n",
    "       cast(substr(latitude, 1, length(latitude)-1) as numeric) * case substr(latitude, length(latitude)) when 'N' then 1 else -1 end as latitude,\n",
    "       cast(substr(longitude, 1, length(longitude)-1) as numeric) * case substr(longitude, length(longitude)) when 'E' then 1 else -1 end as longitude\n",
    " from stg_city_temp\n",
    " where country = 'United States'\n",
    "   and measure_dt between '2012-01-01' and '2012-12-31'\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### Use the size of a city (based on number of zip codes within city boundaries) to break ties and assign states to cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "drop view if exists stg_state_city_xref;\n",
    "create view stg_state_city_xref as\n",
    "select x.*\n",
    "  from (select y.*,\n",
    "               max(y.zip_count) over (partition by y.city_key) as zip_max, \n",
    "               count(*) over (partition by y.city_key) as dups\n",
    "          from (select t.city, t.city_key, a.state_code, a.zip_count\n",
    "                  from (select distinct city_key, city, latitude, longitude \n",
    "                          from stg_us_city_temp) t \n",
    "                  join stg_city_lat_lon_xref a on a.city=t.city and abs(a.latitude - t.latitude)<2.0 and abs(a.longitude - t.longitude)<2.0 \n",
    "               ) y  \n",
    "       ) x\n",
    " where x.zip_count=x.zip_max\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### Now inject state codes from state city xref into city temp dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "3084 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "update stg_us_city_temp t\n",
    "   set state_code = (select x.state_code \n",
    "                         from stg_state_city_xref x \n",
    "                        where t.city_key = x.city_key\n",
    "                          and x.zip_count>1)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "        <th>state_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>720</td>\n",
       "        <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>312</td>\n",
       "        <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>168</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>168</td>\n",
       "        <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>120</td>\n",
       "        <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>96</td>\n",
       "        <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>84</td>\n",
       "        <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>84</td>\n",
       "        <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>84</td>\n",
       "        <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>84</td>\n",
       "        <td>CO</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(720, 'CA'),\n",
       " (312, 'TX'),\n",
       " (168, None),\n",
       " (168, 'FL'),\n",
       " (120, 'AZ'),\n",
       " (96, 'VA'),\n",
       " (84, 'MI'),\n",
       " (84, 'NC'),\n",
       " (84, 'IL'),\n",
       " (84, 'CO')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(*), state_code from stg_us_city_temp group by state_code order by 1 desc limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "14 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>city</th>\n",
       "        <th>latitude</th>\n",
       "        <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Miramar</td>\n",
       "        <td>26.52</td>\n",
       "        <td>-80.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Nuevo Laredo</td>\n",
       "        <td>28.13</td>\n",
       "        <td>-99.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Paradise</td>\n",
       "        <td>36.17</td>\n",
       "        <td>-115.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>East Los Angeles</td>\n",
       "        <td>34.56</td>\n",
       "        <td>-118.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Lakewood</td>\n",
       "        <td>39.38</td>\n",
       "        <td>-104.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Windsor</td>\n",
       "        <td>42.59</td>\n",
       "        <td>-82.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Coral Springs</td>\n",
       "        <td>26.52</td>\n",
       "        <td>-80.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Lexington Fayette</td>\n",
       "        <td>37.78</td>\n",
       "        <td>-85.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Sunrise Manor</td>\n",
       "        <td>36.17</td>\n",
       "        <td>-115.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Thornton</td>\n",
       "        <td>39.38</td>\n",
       "        <td>-104.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Spring Valley</td>\n",
       "        <td>36.17</td>\n",
       "        <td>-115.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Highlands Ranch</td>\n",
       "        <td>39.38</td>\n",
       "        <td>-104.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>West Valley City</td>\n",
       "        <td>40.99</td>\n",
       "        <td>-112.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Overland Park</td>\n",
       "        <td>39.38</td>\n",
       "        <td>-93.64</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Miramar', Decimal('26.52'), Decimal('-80.60')),\n",
       " ('Nuevo Laredo', Decimal('28.13'), Decimal('-99.09')),\n",
       " ('Paradise', Decimal('36.17'), Decimal('-115.36')),\n",
       " ('East Los Angeles', Decimal('34.56'), Decimal('-118.70')),\n",
       " ('Lakewood', Decimal('39.38'), Decimal('-104.05')),\n",
       " ('Windsor', Decimal('42.59'), Decimal('-82.91')),\n",
       " ('Coral Springs', Decimal('26.52'), Decimal('-80.60')),\n",
       " ('Lexington Fayette', Decimal('37.78'), Decimal('-85.42')),\n",
       " ('Sunrise Manor', Decimal('36.17'), Decimal('-115.36')),\n",
       " ('Thornton', Decimal('39.38'), Decimal('-104.05')),\n",
       " ('Spring Valley', Decimal('36.17'), Decimal('-115.36')),\n",
       " ('Highlands Ranch', Decimal('39.38'), Decimal('-104.05')),\n",
       " ('West Valley City', Decimal('40.99'), Decimal('-112.90')),\n",
       " ('Overland Park', Decimal('39.38'), Decimal('-93.64'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This shows cities from the city temp dataset that have no matches in the zip city state xref dataset\n",
    "%sql select distinct city, latitude, longitude from stg_us_city_temp where state_code is null;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### Finally create target \"conformed\" fact table for State Month Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "Done.\n",
      "504 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "drop table if exists i94_state_month_temp_f;\n",
    "create table i94_state_month_temp_f as\n",
    "select state_code, \n",
    "       measure_dt, \n",
    "       measure_yr, \n",
    "       measure_mon, \n",
    "       round(avg(avg_temp),3) avg_temp\n",
    "  from stg_us_city_temp\n",
    " where state_code is not null    -- ignore the ones that didn't match\n",
    " group by state_code, measure_dt, measure_yr, measure_mon\n",
    " order by state_code, measure_dt, measure_yr, measure_mon\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Perform cleaning on staged I94 dataset. \n",
    "* Clean up dtaddto and i94addr columns based on analysis above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "17538 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "update stg_i94\n",
    "   set dtaddto = null\n",
    " where dtaddto='00000000' or dtaddto not similar to '[0-9]*'\n",
    "; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "23890 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "update stg_i94 i\n",
    "   set i94addr = (select state_code\n",
    "                    from i94_ports_entry_d p\n",
    "                   where i.i94port = p.port_code)\n",
    " where i.i94addr is null\n",
    "    or i.i94addr not in (select state_code from i94_states_d)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "* The target data model is a conventional star schema with the I94 data as the primary fact.\n",
    "* There are standard dimensions for elements such as States, Countries, Ports of Entry, Visa Type, etc.\n",
    "* In addition there is a secondary \"conformed\" fact table to contain average temperature data that can be matched against the I94 fact table. In practice this table behaves somewhat like a dimension table but it is a fact table in its own right if used in conjunction with the state dimension.\n",
    "\n",
    "![Conceptual Model](conceptual_model.jpg)\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "* Currently the 'pipeline' is in prototype form and embedded within a Jupyter Notebook.\n",
    "* A production version would create pipeline logic for periodic update of the Global City Temperature dataset as well as the I94 dataset as these grow on a daily basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create I94 Fact table by transforming and loading dataset from I94 staging table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# should convert this to a create table followed by an insert select\n",
    "i94_f_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS i94_f(\n",
    "    cicid BIGINT, \n",
    "    i94yr INT, \n",
    "    i94mon INT, \n",
    "    i94cit VARCHAR,    \n",
    "    i94res VARCHAR,    \n",
    "    i94port VARCHAR, \n",
    "    arrdate DATE,\n",
    "    i94mode VARCHAR, \n",
    "    i94addr VARCHAR, \n",
    "    depdate DATE,\n",
    "    i94age INT,        \n",
    "    i94visa VARCHAR,    \n",
    "    count INT, \n",
    "    dtadfile DATE,\n",
    "    visapost VARCHAR, \n",
    "    occup VARCHAR, \n",
    "    entdepa VARCHAR, \n",
    "    entdepd VARCHAR, \n",
    "    entdepu VARCHAR, \n",
    "    matflag VARCHAR, \n",
    "    biryear INT, \n",
    "    dtaddto DATE, \n",
    "    gender VARCHAR, \n",
    "    insnum VARCHAR, \n",
    "    airline VARCHAR, \n",
    "    admnum VARCHAR, \n",
    "    fltno VARCHAR, \n",
    "    visatype VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "i94_f_drop = \"DROP TABLE IF EXISTS i94_f CASCADE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cur.execute(i94_f_drop)\n",
    "cur.execute(i94_f_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "470476 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "insert into i94_f \n",
    "select cicid, \n",
    "       i94yr, \n",
    "       i94mon,  \n",
    "       replace(i94cit, '.0', '') as i94cit, \n",
    "       replace(i94res, '.0', '') as i94res,\n",
    "       i94port, \n",
    "       to_date('19600101','YYYYMMDD') + cast(arrdate as int) as arrdate,\n",
    "       replace(i94mode,'.0', '') as i94mode,\n",
    "       i94addr, \n",
    "       to_date('19600101','YYYYMMDD') + cast(depdate as int) as depdate,\n",
    "       i94bir as i94age,\n",
    "       replace(i94visa,'.0', '') as i94visa, \n",
    "       count, \n",
    "       to_date(dtadfile, 'YYYYMMDD') as dtadfile,\n",
    "       visapost,\n",
    "       occup,\n",
    "       entdepa,\n",
    "       entdepd,\n",
    "       entdepu,\n",
    "       matflag,\n",
    "       biryear,\n",
    "       to_date(dtaddto, 'MMDDYYYY') as dtaddto,   -- assumes column has been cleansed in staging table via prior update\n",
    "       gender, \n",
    "       insnum, \n",
    "       airline, \n",
    "       fltno, \n",
    "       replace(admnum, '.0', '') as admnum,  \n",
    "       visatype\n",
    "  from stg_i94\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### Perform sanity check queries to confirm data has been loaded for the proper dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "4 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>arrdate</th>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>20467</td>\n",
       "        <td>92151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>20558</td>\n",
       "        <td>107557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>20649</td>\n",
       "        <td>140666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>20741</td>\n",
       "        <td>130102</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(20467, 92151), (20558, 107557), (20649, 140666), (20741, 130102)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select arrdate, count(*) from stg_i94 group by arrdate order by arrdate;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "4 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>arrdate</th>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-01-14</td>\n",
       "        <td>92151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-04-14</td>\n",
       "        <td>107557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-07-14</td>\n",
       "        <td>140666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2016-10-14</td>\n",
       "        <td>130102</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.date(2016, 1, 14), 92151),\n",
       " (datetime.date(2016, 4, 14), 107557),\n",
       " (datetime.date(2016, 7, 14), 140666),\n",
       " (datetime.date(2016, 10, 14), 130102)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select arrdate, count(*) from i94_f group by arrdate order by arrdate;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### Create convenience view on top of I94 fact table. This view instantiates all the joins to associated dimension tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "drop view if exists i94_v;\n",
    "create view i94_v as\n",
    "select i.cicid, \n",
    "       i.i94yr, \n",
    "       i.i94mon, \n",
    "       i.i94cit, c.country_name as cit_country, \n",
    "       i.i94res, r.country_name as res_country,\n",
    "       i.i94port, p.port_of_entry, \n",
    "       i.arrdate,\n",
    "       i.i94mode, m.mode_name,\n",
    "       i.i94addr, s.state_name, \n",
    "       i.depdate,\n",
    "       i.i94age,\n",
    "       i.i94visa, v.visa_name,\n",
    "       i.dtadfile,\n",
    "       i.visapost,\n",
    "       i.occup,\n",
    "       i.entdepa,\n",
    "       i.entdepd,\n",
    "       i.entdepu,\n",
    "       i.matflag,\n",
    "       i.biryear,\n",
    "       i.dtaddto,  \n",
    "       i.gender, \n",
    "       i.insnum, \n",
    "       i.airline, \n",
    "       i.fltno, \n",
    "       i.admnum,  \n",
    "       i.visatype\n",
    "  from i94_f i \n",
    "  left outer join i94_ports_entry_d p on i.i94port = p.port_code   -- never null so use inner join?\n",
    "  left outer join i94_visas_d v on i.i94visa = v.visa_code         -- never null so use inner join?\n",
    "  left outer join i94_modes_d m on i.i94mode = m.mode_code\n",
    "  left outer join i94_countries_d c on i.i94cit = c.country_code\n",
    "  left outer join i94_countries_d r on i.i94res = r.country_code\n",
    "  left outer join i94_states_d s on i.i94addr = s.state_code\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "2 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>470476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>470476</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(470476,), (470476,)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure the row count from the base table is equivalent to the row count from the view\n",
    "%sql select count(*) from i94_f union all select count(*) from i94_v;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### The following queries demonstrate a base query against i94_f and then a similar query which joins to the i94_state_month_temp_f table.\n",
    "- Note that the two queries do not match because the city temperature dataset is missing measures for Hawaii!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>avg_temp</th>\n",
       "        <th>state_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>23.264</td>\n",
       "        <td>FL</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(Decimal('23.264'), 'FL')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select round(avg(avg_temp),3) avg_temp, state_code from i94_state_month_temp_f where state_code in ('HI', 'FL') group by state_code;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "        <th>i94yr</th>\n",
       "        <th>i94mon</th>\n",
       "        <th>i94port</th>\n",
       "        <th>port_of_entry</th>\n",
       "        <th>i94addr</th>\n",
       "        <th>state_name</th>\n",
       "        <th>i94visa</th>\n",
       "        <th>visa_name</th>\n",
       "        <th>i94mode</th>\n",
       "        <th>mode_name</th>\n",
       "        <th>i94cit</th>\n",
       "        <th>cit_country</th>\n",
       "        <th>i94res</th>\n",
       "        <th>res_country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>4370</td>\n",
       "        <td>2016</td>\n",
       "        <td>10</td>\n",
       "        <td>HHW</td>\n",
       "        <td>HONOLULU, HI</td>\n",
       "        <td>HI</td>\n",
       "        <td>HAWAII</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>209</td>\n",
       "        <td>JAPAN</td>\n",
       "        <td>209</td>\n",
       "        <td>JAPAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>4108</td>\n",
       "        <td>2016</td>\n",
       "        <td>7</td>\n",
       "        <td>HHW</td>\n",
       "        <td>HONOLULU, HI</td>\n",
       "        <td>HI</td>\n",
       "        <td>HAWAII</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>209</td>\n",
       "        <td>JAPAN</td>\n",
       "        <td>209</td>\n",
       "        <td>JAPAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3620</td>\n",
       "        <td>2016</td>\n",
       "        <td>4</td>\n",
       "        <td>HHW</td>\n",
       "        <td>HONOLULU, HI</td>\n",
       "        <td>HI</td>\n",
       "        <td>HAWAII</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>209</td>\n",
       "        <td>JAPAN</td>\n",
       "        <td>209</td>\n",
       "        <td>JAPAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3519</td>\n",
       "        <td>2016</td>\n",
       "        <td>1</td>\n",
       "        <td>HHW</td>\n",
       "        <td>HONOLULU, HI</td>\n",
       "        <td>HI</td>\n",
       "        <td>HAWAII</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>209</td>\n",
       "        <td>JAPAN</td>\n",
       "        <td>209</td>\n",
       "        <td>JAPAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3205</td>\n",
       "        <td>2016</td>\n",
       "        <td>10</td>\n",
       "        <td>ORL</td>\n",
       "        <td>ORLANDO, FL</td>\n",
       "        <td>FL</td>\n",
       "        <td>FLORIDA</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>135</td>\n",
       "        <td>UNITED KINGDOM</td>\n",
       "        <td>135</td>\n",
       "        <td>UNITED KINGDOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2489</td>\n",
       "        <td>2016</td>\n",
       "        <td>1</td>\n",
       "        <td>MIA</td>\n",
       "        <td>MIAMI, FL</td>\n",
       "        <td>FL</td>\n",
       "        <td>FLORIDA</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>689</td>\n",
       "        <td>BRAZIL</td>\n",
       "        <td>689</td>\n",
       "        <td>BRAZIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2443</td>\n",
       "        <td>2016</td>\n",
       "        <td>10</td>\n",
       "        <td>NYC</td>\n",
       "        <td>NEW YORK, NY</td>\n",
       "        <td>NY</td>\n",
       "        <td>NEW YORK</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>135</td>\n",
       "        <td>UNITED KINGDOM</td>\n",
       "        <td>135</td>\n",
       "        <td>UNITED KINGDOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2201</td>\n",
       "        <td>2016</td>\n",
       "        <td>7</td>\n",
       "        <td>LOS</td>\n",
       "        <td>LOS ANGELES, CA</td>\n",
       "        <td>CA</td>\n",
       "        <td>CALIFORNIA</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>245</td>\n",
       "        <td>CHINA, PRC</td>\n",
       "        <td>245</td>\n",
       "        <td>CHINA, PRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1984</td>\n",
       "        <td>2016</td>\n",
       "        <td>4</td>\n",
       "        <td>NYC</td>\n",
       "        <td>NEW YORK, NY</td>\n",
       "        <td>NY</td>\n",
       "        <td>NEW YORK</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>111</td>\n",
       "        <td>FRANCE</td>\n",
       "        <td>111</td>\n",
       "        <td>FRANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1926</td>\n",
       "        <td>2016</td>\n",
       "        <td>7</td>\n",
       "        <td>MIA</td>\n",
       "        <td>MIAMI, FL</td>\n",
       "        <td>FL</td>\n",
       "        <td>FLORIDA</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>687</td>\n",
       "        <td>ARGENTINA </td>\n",
       "        <td>687</td>\n",
       "        <td>ARGENTINA </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(4370, 2016, 10, 'HHW', 'HONOLULU, HI', 'HI', 'HAWAII', '2', 'Pleasure', '1', 'Air', '209', 'JAPAN', '209', 'JAPAN'),\n",
       " (4108, 2016, 7, 'HHW', 'HONOLULU, HI', 'HI', 'HAWAII', '2', 'Pleasure', '1', 'Air', '209', 'JAPAN', '209', 'JAPAN'),\n",
       " (3620, 2016, 4, 'HHW', 'HONOLULU, HI', 'HI', 'HAWAII', '2', 'Pleasure', '1', 'Air', '209', 'JAPAN', '209', 'JAPAN'),\n",
       " (3519, 2016, 1, 'HHW', 'HONOLULU, HI', 'HI', 'HAWAII', '2', 'Pleasure', '1', 'Air', '209', 'JAPAN', '209', 'JAPAN'),\n",
       " (3205, 2016, 10, 'ORL', 'ORLANDO, FL', 'FL', 'FLORIDA', '2', 'Pleasure', '1', 'Air', '135', 'UNITED KINGDOM', '135', 'UNITED KINGDOM'),\n",
       " (2489, 2016, 1, 'MIA', 'MIAMI, FL', 'FL', 'FLORIDA', '2', 'Pleasure', '1', 'Air', '689', 'BRAZIL', '689', 'BRAZIL'),\n",
       " (2443, 2016, 10, 'NYC', 'NEW YORK, NY', 'NY', 'NEW YORK', '2', 'Pleasure', '1', 'Air', '135', 'UNITED KINGDOM', '135', 'UNITED KINGDOM'),\n",
       " (2201, 2016, 7, 'LOS', 'LOS ANGELES, CA', 'CA', 'CALIFORNIA', '2', 'Pleasure', '1', 'Air', '245', 'CHINA, PRC', '245', 'CHINA, PRC'),\n",
       " (1984, 2016, 4, 'NYC', 'NEW YORK, NY', 'NY', 'NEW YORK', '2', 'Pleasure', '1', 'Air', '111', 'FRANCE', '111', 'FRANCE'),\n",
       " (1926, 2016, 7, 'MIA', 'MIAMI, FL', 'FL', 'FLORIDA', '2', 'Pleasure', '1', 'Air', '687', 'ARGENTINA ', '687', 'ARGENTINA ')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "select count(*), \n",
    "       i94yr, i94mon,\n",
    "       i94port, port_of_entry, i94addr, state_name,\n",
    "       i94visa, visa_name, i94mode, mode_name, \n",
    "       i94cit, cit_country, i94res, res_country\n",
    "  from i94_v i \n",
    " where 1=1\n",
    " group by i94yr, i94mon, \n",
    "          i94port, port_of_entry, i94addr, state_name,\n",
    "          i94visa, visa_name, i94mode, mode_name, \n",
    "          i94cit, cit_country, i94res, res_country\n",
    " order by 1 desc\n",
    " limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "        <th>i94yr</th>\n",
       "        <th>i94mon</th>\n",
       "        <th>avg_temp</th>\n",
       "        <th>i94port</th>\n",
       "        <th>port_of_entry</th>\n",
       "        <th>i94addr</th>\n",
       "        <th>state_name</th>\n",
       "        <th>i94visa</th>\n",
       "        <th>visa_name</th>\n",
       "        <th>i94mode</th>\n",
       "        <th>mode_name</th>\n",
       "        <th>i94cit</th>\n",
       "        <th>cit_country</th>\n",
       "        <th>i94res</th>\n",
       "        <th>res_country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3205</td>\n",
       "        <td>2016</td>\n",
       "        <td>10</td>\n",
       "        <td>24.356</td>\n",
       "        <td>ORL</td>\n",
       "        <td>ORLANDO, FL</td>\n",
       "        <td>FL</td>\n",
       "        <td>FLORIDA</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>135</td>\n",
       "        <td>UNITED KINGDOM</td>\n",
       "        <td>135</td>\n",
       "        <td>UNITED KINGDOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2489</td>\n",
       "        <td>2016</td>\n",
       "        <td>1</td>\n",
       "        <td>16.826</td>\n",
       "        <td>MIA</td>\n",
       "        <td>MIAMI, FL</td>\n",
       "        <td>FL</td>\n",
       "        <td>FLORIDA</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>689</td>\n",
       "        <td>BRAZIL</td>\n",
       "        <td>689</td>\n",
       "        <td>BRAZIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2443</td>\n",
       "        <td>2016</td>\n",
       "        <td>10</td>\n",
       "        <td>11.480</td>\n",
       "        <td>NYC</td>\n",
       "        <td>NEW YORK, NY</td>\n",
       "        <td>NY</td>\n",
       "        <td>NEW YORK</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>135</td>\n",
       "        <td>UNITED KINGDOM</td>\n",
       "        <td>135</td>\n",
       "        <td>UNITED KINGDOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2201</td>\n",
       "        <td>2016</td>\n",
       "        <td>7</td>\n",
       "        <td>22.068</td>\n",
       "        <td>LOS</td>\n",
       "        <td>LOS ANGELES, CA</td>\n",
       "        <td>CA</td>\n",
       "        <td>CALIFORNIA</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>245</td>\n",
       "        <td>CHINA, PRC</td>\n",
       "        <td>245</td>\n",
       "        <td>CHINA, PRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1984</td>\n",
       "        <td>2016</td>\n",
       "        <td>4</td>\n",
       "        <td>8.162</td>\n",
       "        <td>NYC</td>\n",
       "        <td>NEW YORK, NY</td>\n",
       "        <td>NY</td>\n",
       "        <td>NEW YORK</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>111</td>\n",
       "        <td>FRANCE</td>\n",
       "        <td>111</td>\n",
       "        <td>FRANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1926</td>\n",
       "        <td>2016</td>\n",
       "        <td>7</td>\n",
       "        <td>28.175</td>\n",
       "        <td>MIA</td>\n",
       "        <td>MIAMI, FL</td>\n",
       "        <td>FL</td>\n",
       "        <td>FLORIDA</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>687</td>\n",
       "        <td>ARGENTINA </td>\n",
       "        <td>687</td>\n",
       "        <td>ARGENTINA </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1857</td>\n",
       "        <td>2016</td>\n",
       "        <td>7</td>\n",
       "        <td>28.175</td>\n",
       "        <td>ORL</td>\n",
       "        <td>ORLANDO, FL</td>\n",
       "        <td>FL</td>\n",
       "        <td>FLORIDA</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>135</td>\n",
       "        <td>UNITED KINGDOM</td>\n",
       "        <td>135</td>\n",
       "        <td>UNITED KINGDOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1715</td>\n",
       "        <td>2016</td>\n",
       "        <td>10</td>\n",
       "        <td>24.356</td>\n",
       "        <td>MIA</td>\n",
       "        <td>MIAMI, FL</td>\n",
       "        <td>FL</td>\n",
       "        <td>FLORIDA</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>687</td>\n",
       "        <td>ARGENTINA </td>\n",
       "        <td>687</td>\n",
       "        <td>ARGENTINA </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1671</td>\n",
       "        <td>2016</td>\n",
       "        <td>4</td>\n",
       "        <td>8.162</td>\n",
       "        <td>NYC</td>\n",
       "        <td>NEW YORK, NY</td>\n",
       "        <td>NY</td>\n",
       "        <td>NEW YORK</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>135</td>\n",
       "        <td>UNITED KINGDOM</td>\n",
       "        <td>135</td>\n",
       "        <td>UNITED KINGDOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1646</td>\n",
       "        <td>2016</td>\n",
       "        <td>1</td>\n",
       "        <td>16.826</td>\n",
       "        <td>ORL</td>\n",
       "        <td>ORLANDO, FL</td>\n",
       "        <td>FL</td>\n",
       "        <td>FLORIDA</td>\n",
       "        <td>2</td>\n",
       "        <td>Pleasure</td>\n",
       "        <td>1</td>\n",
       "        <td>Air</td>\n",
       "        <td>689</td>\n",
       "        <td>BRAZIL</td>\n",
       "        <td>689</td>\n",
       "        <td>BRAZIL</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(3205, 2016, 10, Decimal('24.356'), 'ORL', 'ORLANDO, FL', 'FL', 'FLORIDA', '2', 'Pleasure', '1', 'Air', '135', 'UNITED KINGDOM', '135', 'UNITED KINGDOM'),\n",
       " (2489, 2016, 1, Decimal('16.826'), 'MIA', 'MIAMI, FL', 'FL', 'FLORIDA', '2', 'Pleasure', '1', 'Air', '689', 'BRAZIL', '689', 'BRAZIL'),\n",
       " (2443, 2016, 10, Decimal('11.480'), 'NYC', 'NEW YORK, NY', 'NY', 'NEW YORK', '2', 'Pleasure', '1', 'Air', '135', 'UNITED KINGDOM', '135', 'UNITED KINGDOM'),\n",
       " (2201, 2016, 7, Decimal('22.068'), 'LOS', 'LOS ANGELES, CA', 'CA', 'CALIFORNIA', '2', 'Pleasure', '1', 'Air', '245', 'CHINA, PRC', '245', 'CHINA, PRC'),\n",
       " (1984, 2016, 4, Decimal('8.162'), 'NYC', 'NEW YORK, NY', 'NY', 'NEW YORK', '2', 'Pleasure', '1', 'Air', '111', 'FRANCE', '111', 'FRANCE'),\n",
       " (1926, 2016, 7, Decimal('28.175'), 'MIA', 'MIAMI, FL', 'FL', 'FLORIDA', '2', 'Pleasure', '1', 'Air', '687', 'ARGENTINA ', '687', 'ARGENTINA '),\n",
       " (1857, 2016, 7, Decimal('28.175'), 'ORL', 'ORLANDO, FL', 'FL', 'FLORIDA', '2', 'Pleasure', '1', 'Air', '135', 'UNITED KINGDOM', '135', 'UNITED KINGDOM'),\n",
       " (1715, 2016, 10, Decimal('24.356'), 'MIA', 'MIAMI, FL', 'FL', 'FLORIDA', '2', 'Pleasure', '1', 'Air', '687', 'ARGENTINA ', '687', 'ARGENTINA '),\n",
       " (1671, 2016, 4, Decimal('8.162'), 'NYC', 'NEW YORK, NY', 'NY', 'NEW YORK', '2', 'Pleasure', '1', 'Air', '135', 'UNITED KINGDOM', '135', 'UNITED KINGDOM'),\n",
       " (1646, 2016, 1, Decimal('16.826'), 'ORL', 'ORLANDO, FL', 'FL', 'FLORIDA', '2', 'Pleasure', '1', 'Air', '689', 'BRAZIL', '689', 'BRAZIL')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "select count(*), \n",
    "       i94yr, i94mon, t.avg_temp,\n",
    "       i94port, port_of_entry, i94addr, state_name,\n",
    "       i94visa, visa_name, i94mode, mode_name, \n",
    "       i94cit, cit_country, i94res, res_country\n",
    "  from i94_v i\n",
    "  join i94_state_month_temp_f t on i94yr=measure_yr and i94mon=measure_mon and i94addr=state_code  \n",
    " where 1=1\n",
    " group by i94yr, i94mon, avg_temp,\n",
    "          i94port, port_of_entry, i94addr, state_name,\n",
    "          i94visa, visa_name, i94mode, mode_name, \n",
    "          i94cit, cit_country, i94res, res_country\n",
    " order by 1 desc\n",
    " limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Sample queries simulating analysis of tourism patterns related to months/weather...\n",
    "* first initialize the rudimentary pivot table feature of PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "drop extension if exists tablefunc;\n",
    "create extension tablefunc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "drop view if exists captain_obvious;\n",
    "create view captain_obvious as\n",
    "select count(*)::int as tourists, \n",
    "       (case i94mon when 1 then 'JAN' when 4 then 'APR' when 7 then 'JUL' when 10 then 'OCT' end)::text as mon,\n",
    "       i94yr, i94mon, \n",
    "       round(avg(t.avg_temp),1) avg_temp,\n",
    "       i94addr, state_name::text\n",
    "  from i94_v i\n",
    "  join i94_state_month_temp_f t on i94yr=measure_yr and i94mon=measure_mon and i94addr=state_code  \n",
    " where i94visa='2'\n",
    "   and i94addr in ('AK', 'CA', 'FL', 'NY', 'TX', 'AZ', 'CO', 'LA')\n",
    " group by i94yr, i94mon, \n",
    "          i94addr, state_name\n",
    " order by i94addr, i94yr, i94mon\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "12 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>tourists</th>\n",
       "        <th>mon</th>\n",
       "        <th>i94yr</th>\n",
       "        <th>i94mon</th>\n",
       "        <th>avg_temp</th>\n",
       "        <th>i94addr</th>\n",
       "        <th>state_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>30</td>\n",
       "        <td>JAN</td>\n",
       "        <td>2016</td>\n",
       "        <td>1</td>\n",
       "        <td>-22.6</td>\n",
       "        <td>AK</td>\n",
       "        <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>38</td>\n",
       "        <td>APR</td>\n",
       "        <td>2016</td>\n",
       "        <td>4</td>\n",
       "        <td>0.4</td>\n",
       "        <td>AK</td>\n",
       "        <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>425</td>\n",
       "        <td>JUL</td>\n",
       "        <td>2016</td>\n",
       "        <td>7</td>\n",
       "        <td>10.7</td>\n",
       "        <td>AK</td>\n",
       "        <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>52</td>\n",
       "        <td>OCT</td>\n",
       "        <td>2016</td>\n",
       "        <td>10</td>\n",
       "        <td>-3.6</td>\n",
       "        <td>AK</td>\n",
       "        <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>397</td>\n",
       "        <td>JAN</td>\n",
       "        <td>2016</td>\n",
       "        <td>1</td>\n",
       "        <td>12.2</td>\n",
       "        <td>AZ</td>\n",
       "        <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>507</td>\n",
       "        <td>APR</td>\n",
       "        <td>2016</td>\n",
       "        <td>4</td>\n",
       "        <td>20.7</td>\n",
       "        <td>AZ</td>\n",
       "        <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>700</td>\n",
       "        <td>JUL</td>\n",
       "        <td>2016</td>\n",
       "        <td>7</td>\n",
       "        <td>31.2</td>\n",
       "        <td>AZ</td>\n",
       "        <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>597</td>\n",
       "        <td>OCT</td>\n",
       "        <td>2016</td>\n",
       "        <td>10</td>\n",
       "        <td>22.5</td>\n",
       "        <td>AZ</td>\n",
       "        <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>11305</td>\n",
       "        <td>JAN</td>\n",
       "        <td>2016</td>\n",
       "        <td>1</td>\n",
       "        <td>11.5</td>\n",
       "        <td>CA</td>\n",
       "        <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>15038</td>\n",
       "        <td>APR</td>\n",
       "        <td>2016</td>\n",
       "        <td>4</td>\n",
       "        <td>14.7</td>\n",
       "        <td>CA</td>\n",
       "        <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>24114</td>\n",
       "        <td>JUL</td>\n",
       "        <td>2016</td>\n",
       "        <td>7</td>\n",
       "        <td>22.1</td>\n",
       "        <td>CA</td>\n",
       "        <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>18290</td>\n",
       "        <td>OCT</td>\n",
       "        <td>2016</td>\n",
       "        <td>10</td>\n",
       "        <td>18.5</td>\n",
       "        <td>CA</td>\n",
       "        <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(30, 'JAN', 2016, 1, Decimal('-22.6'), 'AK', 'ALASKA'),\n",
       " (38, 'APR', 2016, 4, Decimal('0.4'), 'AK', 'ALASKA'),\n",
       " (425, 'JUL', 2016, 7, Decimal('10.7'), 'AK', 'ALASKA'),\n",
       " (52, 'OCT', 2016, 10, Decimal('-3.6'), 'AK', 'ALASKA'),\n",
       " (397, 'JAN', 2016, 1, Decimal('12.2'), 'AZ', 'ARIZONA'),\n",
       " (507, 'APR', 2016, 4, Decimal('20.7'), 'AZ', 'ARIZONA'),\n",
       " (700, 'JUL', 2016, 7, Decimal('31.2'), 'AZ', 'ARIZONA'),\n",
       " (597, 'OCT', 2016, 10, Decimal('22.5'), 'AZ', 'ARIZONA'),\n",
       " (11305, 'JAN', 2016, 1, Decimal('11.5'), 'CA', 'CALIFORNIA'),\n",
       " (15038, 'APR', 2016, 4, Decimal('14.7'), 'CA', 'CALIFORNIA'),\n",
       " (24114, 'JUL', 2016, 7, Decimal('22.1'), 'CA', 'CALIFORNIA'),\n",
       " (18290, 'OCT', 2016, 10, Decimal('18.5'), 'CA', 'CALIFORNIA')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select * from captain_obvious limit 12;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "8 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>state_name</th>\n",
       "        <th>jan</th>\n",
       "        <th>apr</th>\n",
       "        <th>jul</th>\n",
       "        <th>oct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ALASKA</td>\n",
       "        <td>-22.6</td>\n",
       "        <td>0.4</td>\n",
       "        <td>10.7</td>\n",
       "        <td>-3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ARIZONA</td>\n",
       "        <td>12.2</td>\n",
       "        <td>20.7</td>\n",
       "        <td>31.2</td>\n",
       "        <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>CALIFORNIA</td>\n",
       "        <td>11.5</td>\n",
       "        <td>14.7</td>\n",
       "        <td>22.1</td>\n",
       "        <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>COLORADO</td>\n",
       "        <td>-0.1</td>\n",
       "        <td>10.1</td>\n",
       "        <td>23.3</td>\n",
       "        <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>FLORIDA</td>\n",
       "        <td>16.8</td>\n",
       "        <td>22.5</td>\n",
       "        <td>28.2</td>\n",
       "        <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>LOUISIANA</td>\n",
       "        <td>14.1</td>\n",
       "        <td>21.6</td>\n",
       "        <td>28.4</td>\n",
       "        <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>NEW YORK</td>\n",
       "        <td>-1.2</td>\n",
       "        <td>8.2</td>\n",
       "        <td>23.7</td>\n",
       "        <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>TEXAS</td>\n",
       "        <td>10.6</td>\n",
       "        <td>21.2</td>\n",
       "        <td>29.5</td>\n",
       "        <td>19.3</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('ALASKA', Decimal('-22.6'), Decimal('0.4'), Decimal('10.7'), Decimal('-3.6')),\n",
       " ('ARIZONA', Decimal('12.2'), Decimal('20.7'), Decimal('31.2'), Decimal('22.5')),\n",
       " ('CALIFORNIA', Decimal('11.5'), Decimal('14.7'), Decimal('22.1'), Decimal('18.5')),\n",
       " ('COLORADO', Decimal('-0.1'), Decimal('10.1'), Decimal('23.3'), Decimal('8.2')),\n",
       " ('FLORIDA', Decimal('16.8'), Decimal('22.5'), Decimal('28.2'), Decimal('24.4')),\n",
       " ('LOUISIANA', Decimal('14.1'), Decimal('21.6'), Decimal('28.4'), Decimal('20.1')),\n",
       " ('NEW YORK', Decimal('-1.2'), Decimal('8.2'), Decimal('23.7'), Decimal('11.5')),\n",
       " ('TEXAS', Decimal('10.6'), Decimal('21.2'), Decimal('29.5'), Decimal('19.3'))]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * \n",
    "from crosstab (\n",
    "'SELECT state_name, mon, avg_temp\n",
    "   FROM captain_obvious\n",
    "  ORDER BY state_name, i94mon'\n",
    ") as result (state_name TEXT, JAN numeric, APR numeric, JUL numeric, OCT numeric)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/capstone\n",
      "8 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>state_name</th>\n",
       "        <th>jan</th>\n",
       "        <th>apr</th>\n",
       "        <th>jul</th>\n",
       "        <th>oct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ALASKA</td>\n",
       "        <td>30</td>\n",
       "        <td>38</td>\n",
       "        <td>425</td>\n",
       "        <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ARIZONA</td>\n",
       "        <td>397</td>\n",
       "        <td>507</td>\n",
       "        <td>700</td>\n",
       "        <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>CALIFORNIA</td>\n",
       "        <td>11305</td>\n",
       "        <td>15038</td>\n",
       "        <td>24114</td>\n",
       "        <td>18290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>COLORADO</td>\n",
       "        <td>662</td>\n",
       "        <td>395</td>\n",
       "        <td>1055</td>\n",
       "        <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>FLORIDA</td>\n",
       "        <td>21359</td>\n",
       "        <td>21423</td>\n",
       "        <td>26741</td>\n",
       "        <td>30558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>LOUISIANA</td>\n",
       "        <td>286</td>\n",
       "        <td>667</td>\n",
       "        <td>600</td>\n",
       "        <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>NEW YORK</td>\n",
       "        <td>10510</td>\n",
       "        <td>19185</td>\n",
       "        <td>23335</td>\n",
       "        <td>24360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>TEXAS</td>\n",
       "        <td>3007</td>\n",
       "        <td>3631</td>\n",
       "        <td>5116</td>\n",
       "        <td>4318</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('ALASKA', 30, 38, 425, 52),\n",
       " ('ARIZONA', 397, 507, 700, 597),\n",
       " ('CALIFORNIA', 11305, 15038, 24114, 18290),\n",
       " ('COLORADO', 662, 395, 1055, 561),\n",
       " ('FLORIDA', 21359, 21423, 26741, 30558),\n",
       " ('LOUISIANA', 286, 667, 600, 463),\n",
       " ('NEW YORK', 10510, 19185, 23335, 24360),\n",
       " ('TEXAS', 3007, 3631, 5116, 4318)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * \n",
    "from crosstab (\n",
    "'SELECT state_name, mon, tourists\n",
    "   FROM captain_obvious\n",
    "  ORDER BY state_name, i94mon'\n",
    ") as result (state_name TEXT, JAN INT, APR INT, JUL INT, OCT INT)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### From the above we determine the earthshattering analysis:\n",
    "1. More people visit Alaska, Arizona, and California in the summer.\n",
    "2. That is true of Colorado as well but there are a large number of tourists in winter as well (skiing)\n",
    "3. Florida has a high season in the fall (snowbirds)\n",
    "3. Louisiana has a high season in spring (Mardi Gras)\n",
    "4. New York is popular in the summer and fall\n",
    "5. Texas? Meh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "##### i94_f - I94 Fact table\n",
    "* I94YR - 4 digit year \n",
    "* I94MON - Numeric month \n",
    "* I94CIT - Country of Citizenship  \n",
    "* I94RES - Country of Residence \n",
    "* I94PORT - This format shows all the valid and invalid codes for processing \n",
    "* ARRDATE - the Arrival Date in the USA. \n",
    "* I94MODE - Mode of arrival: 1 = 'Air'; 2 = 'Sea'; 3 = 'Land'; 9 = 'Not reported' \n",
    "* I94ADDR - Represents the ultimate destination US state of the traveller. There are a lot of invalid codes in the data.\n",
    "* DEPDATE - the Departure Date from the USA. It is a SAS date numeric field that\n",
    "* I94BIR - Age of Respondent in Years \n",
    "* I94VISA - Visa codes collapsed into three categories: 1 = Business; 2 = Pleasure; 3 = Student \n",
    "* COUNT - Used for summary statistics \n",
    "* DTADFILE - Character Date Field - Date added to I-94 Files - CIC does not use \n",
    "* VISAPOST - Department of State where where Visa was issued - CIC does not use \n",
    "* OCCUP - Occupation that will be performed in U.S. - CIC does not use \n",
    "* ENTDEPA - Arrival Flag - admitted or paroled into the U.S. - CIC does not use \n",
    "* ENTDEPD - Departure Flag - Departed, lost I-94 or is deceased - CIC does not use \n",
    "* ENTDEPU - Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use \n",
    "* MATFLAG - Match flag - Match of arrival and departure records \n",
    "* BIRYEAR - 4 digit year of birth \n",
    "* DTADDTO - Character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use \n",
    "* GENDER - Non-immigrant sex \n",
    "* INSNUM - INS number \n",
    "* AIRLINE - Airline used to arrive in U.S. \n",
    "* ADMNUM - Admission Number \n",
    "* FLTNO - Flight number of Airline used to arrive in U.S. \n",
    "* VISATYPE - Class of admission legally admitting the non-immigrant to temporarily stay in U.S. *  \n",
    "\n",
    "##### i94_states_d - States Dimension table\n",
    "* state_code - state code\n",
    "* state_name - state name\n",
    "\n",
    "##### i94_countries_d - Countries Dimension table\n",
    "* country_code - country code\n",
    "* country_name - country name\n",
    "\n",
    "##### i94_ports_entry_d - Ports of Entry Dimension Table\n",
    "* port_code - port of entry code\n",
    "* port_of_entry - port of entry name\n",
    "* state_code - state code\n",
    "\n",
    "##### i94_modes_d - I94 Modes Dimension table\n",
    "* mode_code - mode code \n",
    "* mode_name - mode name (i.e. Air, Sea, Land)\n",
    "\n",
    "##### i94_visas_d - I94 Visas Dimension table\n",
    "* visa_code - visa code \n",
    "* visa_name - visa name (i.e. Business, Student, Pleasure)\n",
    "\n",
    "##### i94_state_month_temp_f - State Month Temperatore fact table (correlated fact))\n",
    "* state_code - state code\n",
    "* measure_dt - measurement date\n",
    "* measure_yr - measurement year\n",
    "* measure_mon - measurement month\n",
    "* avg_temp - average temperature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "  * As described earlier, the primary tool PostgreSQL is a stand-in for Redshift.\n",
    "* Propose how often the data should be updated and why.\n",
    "  * This depends on what hypothetical end users would require. However it seems likely that both the I94 and Global City Temperature data should be updated consistently on a daily to weekly basis. The other datasets are primarily static in nature although there might be some occasional updates.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "   * The database would need to be upgraded to one of the tools that can scale to that degree. So something like Redshift, Cassandra, or some combination of cloud based Spark with parquet files and/or Hive based relational repository could be used.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "   * A scheduling management/orchestration tool such as Airflow could be integrated into the data pipeline for loading I94 and/or City Temperature data. \n",
    " * The database needed to be accessed by 100+ people.\n",
    "   * The same upgrade mentioned above for data increase could be useful to maintain performance for higher query traffic.\n",
    "   * Most of the cloud based tools can benefit from almost linear scaling by increasing the number and power of server cluster nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
